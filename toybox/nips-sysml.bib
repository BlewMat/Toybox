@inproceedings{cohen2018distributed,
author = {Cohen, Daniel and Jordan, Scott M. and Croft, W. Bruce},
title = {Distributed Evaluations: Ending Neural Point Metrics},
year = {2018},
booktitle = {SIGIR; LND4IR},
type = {IR},
}

@inproceedings{clary2018variability,
title={{Letâ€™s Play Again: Variability of Deep Reinforcement Learning Agents in Atari Environments}},
author={Clary, Kaleigh and Tosch, Emma and Foley, John and Jensen, David},
booktitle={{NeurIPS 2018 Workshop on Critiquing and Correcting Trends in Machine Learning}},
year={2018}
}

@inproceedings{jordan2018benchmarks,
title={{Using Cumulative Distribution Based Performance Analysis to Bechmark Models}},
author={Jordan, Scott M. and Cohen, Daniel and Thomas, Phillip S.},
booktitle={{NeurIPS 2018 Workshop on Critiquing and Correcting Trends in Machine Learning}},
year={2018}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={{International conference on Machine Learning}},
  pages={1928--1937},
  year={2016}
}

@misc{OpenAI_ppo,
  author = {{OpenAI}},
  title = {{Proximal Policy Optimization}},
  howpublished = {\url{https://blog.openai.com/openai-baselines-ppo/}},
  year = {2017}}

@misc{rlblogpost,
    title={Deep Reinforcement Learning Doesn't Work Yet},
    author={Irpan, Alex},
    howpublished={\url{https://www.alexirpan.com/2018/02/14/rl-hard.html}},
    year={2018}
}


@article{hwangbo2017control,
  title={{Control of a Quadrotor with Reinforcement Learning}},
  author={Hwangbo, Jemin and Sa, Inkyu and Siegwart, Roland and Hutter, Marco},
  journal={IEEE Robotics and Automation Letters},
  volume={2},
  number={4},
  pages={2096--2103},
  year={2017},
  publisher={IEEE}
}

@inproceedings{wu2017scalable,
  title={Scalable trust-region method for deep reinforcement learning using kronecker-factored approximation},
  author={Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  booktitle={Advances in neural information processing systems},
  pages={5279--5288},
  year={2017}
}

@article{schulman2017proximal,
  title={{Proximal Policy Optimization Algorithms}},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{berseth2018terrain,
  title={{Terrain RL Simulator}},
  author={Berseth, Glen and Peng, Xue Bin and van de Panne, Michiel},
  journal={arXiv preprint arXiv:1804.06424},
  year={2018}
}

@article{lucas2018game,
  title={{Game AI Research with Fast Planet Wars Variants}},
  author={Lucas, Simon M},
  journal={arXiv preprint arXiv:1806.08544},
  year={2018}
}

@inproceedings{todorov2012mujoco,
  title={{Mujoco: A Physics Engine for Model-based Control}},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{synnaeve2016torchcraft,
  title={{Torchcraft: a Library for Machine Learning Research on Real-time Strategy Games}},
  author={Synnaeve, Gabriel and Nardelli, Nantas and Auvolat, Alex and Chintala, Soumith and Lacroix, Timoth{\'e}e and Lin, Zeming and Richoux, Florian and Usunier, Nicolas},
  journal={arXiv preprint arXiv:1611.00625},
  year={2016}
}

@article{vinyals2017starcraft,
  title={{{Starcraft II}: A New Challenge for Reinforcement Learning}},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}

@article{arulkumaran2017brief,
  title={{A Brief Survey of Deep Reinforcement Learning}},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={arXiv preprint arXiv:1708.05866},
  year={2017}
}

@incollection{NIPS2017_6859,
title = {{ELF: An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games}},
author = {Tian, Yuandong and Gong, Qucheng and Shang, Wenling and Wu, Yuxin and Zitnick, C. Lawrence},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {2659--2669},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6859-elf-an-extensive-lightweight-and-flexible-research-platform-for-real-time-strategy-games.pdf}
}


@article{moore1990efficient,
  title={Efficient memory-based learning for robot control},
  author={Moore, Andrew William},
  year={1990},
  publisher={Citeseer}
}

@article{barto1983neuronlike,
  title={Neuronlike adaptive elements that can solve difficult learning control problems},
  author={Barto, Andrew G and Sutton, Richard S and Anderson, Charles W},
  journal={IEEE transactions on systems, man, and cybernetics},
  number={5},
  pages={834--846},
  year={1983},
  publisher={IEEE}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G and others},
  year={1998},
  publisher={MIT press}
}

@article{raghu2017can,
  title={{Can Deep Reinforcement Learning solve Erdos-Selfridge-Spencer Games?}},
  author={Raghu, Maithra and Irpan, Alex and Andreas, Jacob and Kleinberg, Robert and Le, Quoc V and Kleinberg, Jon},
  journal={arXiv preprint arXiv:1711.02301},
  year={2017}
}

@article{zhang2016understanding,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2016}
}

@article{zhang2018study,
  title={A Study on Overfitting in Deep Reinforcement Learning},
  author={Zhang, Chiyuan and Vinyals, Oriol and Munos, Remi and Bengio, Samy},
  journal={arXiv preprint arXiv:1804.06893},
  year={2018}
}

@article{sobol2018visual,
  title={{Visual Analogies between Atari Games for Studying Transfer Learning in RL}},
  author={Sobol, Doron and Wolf, Lior and Taigman, Yaniv},
  year={2018}
}

@inproceedings{whiteson2011protecting,
  title={{Protecting against Evaluation Overfitting in Empirical Reinforcement Learning}},
  author={Whiteson, Shimon and Tanner, Brian and Taylor, Matthew E and Stone, Peter},
  booktitle={Adaptive Dynamic Programming And Reinforcement Learning (ADPRL), 2011 IEEE Symposium on},
  pages={120--127},
  year={2011},
  organization={IEEE}
}

@article{pohlen2018observe,
  title={Observe and Look Further: Achieving Consistent Performance on Atari},
  author={Pohlen, Tobias and Piot, Bilal and Hester, Todd and Azar, Mohammad Gheshlaghi and Horgan, Dan and Budden, David and Barth-Maron, Gabriel and van Hasselt, Hado and Quan, John and Ve{\v{c}}er{\'\i}k, Mel and others},
  journal={arXiv preprint arXiv:1805.11593},
  year={2018}
}

@article{mnih2013playing,
  title={{Playing Atari with Deep Reinforcement Learning}},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}
@article{mnih2015nature,
	Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	Date = {2015/02/25/online},
	Date-Added = {2018-10-15 17:20:18 +0000},
	Date-Modified = {2018-10-15 17:20:42 +0000},
	Day = {25},
	Journal = {Nature},
	L3 = {10.1038/nature14236; https://www.nature.com/articles/nature14236#supplementary-information},
	Month = {02},
	Pages = {529 EP  -},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved. SN  -},
	Title = {{Human-level Control through Deep Reinforcement Learning}},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/nature14236},
	Volume = {518},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nature14236}}
% open-AI-gym
@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {{OpenAI Gym}},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}
% open-AI-gym-baselines
@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {{OpenAI Baselines}},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@Article{bellemare13arcade,
  author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
  title = {{The Arcade Learning Environment: An Evaluation Platform for General Agents}},
  journal = {Journal of Artificial Intelligence Research},
  year = "2013",
  month = "jun",
  volume = "47",
  pages = "253--279",
}
@Article{machado17arcade,
  author = {Marlos C. Machado and Marc G. Bellemare and Erik Talvitie and Joel Veness and Matthew J. Hausknecht and Michael Bowling},
  title = {{Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents}},
  journal = {CoRR},
  volume = {abs/1709.06009},
  year = {2017}
}

% Pacman AI overflow bug
@misc {pacmanOverflow,
  author = {Don Hodges},
  title = {{Why do Pinky and Inky have different behaviors when Pac-Man is facing up?}},
  howpublished={\url{http://donhodges.com/pacman_pinky_explanation.htm}},
  year={2015}
}

% Servo-Rust
@inproceedings{anderson2016engineering,
  title={{Engineering the servo web browser engine using Rust}},
  author={Anderson, Brian and Bergstrom, Lars and Goregaokar, Manish and Matthews, Josh and McAllister, Keegan and Moffitt, Jack and Sapin, Simon},
  booktitle={Proceedings of the 38th International Conference on Software Engineering Companion},
  pages={81--89},
  year={2016},
  organization={ACM}
}
% Securing Rust (POPL)
@article{jung2017rustbelt,
  title={{RustBelt: Securing the foundations of the Rust programming language}},
  author={Jung, Ralf and Jourdan, Jacques-Henri and Krebbers, Robbert and Dreyer, Derek},
  journal={Proceedings of the ACM on Programming Languages},
  volume={2},
  number={POPL},
  pages={66},
  year={2017},
  publisher={ACM}
}
% Rust in the browser
@misc {rustBrowser,
    author={Alex Crichton},
    year={2018},
    title={{JavaScript to Rust and Back Again: A wasm-bindgen Tale}},
    howpublished={\url{https://hacks.mozilla.org/2018/04/javascript-to-rust-and-back-again-a-wasm-bindgen-tale/}}
}